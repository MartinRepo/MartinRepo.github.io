---
title: "高性能计算(COMP328)"
date: 2024-02-03T17:39:49Z
draft: false
author: "Martin"
tags: 
- 高性能计算
description: ""
weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序
slug: ""
comments: true
showToc: true # 显示目录
TocOpen: true # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示当前路径
cover:
    image: ""
    caption: ""
    alt: ""
    relative: false
mermaid: true
---
# Week1
高性能计算的目标
- 对于有限的数据集，最小化解决时间
- 对于无限的数据集，最大化吞吐量(throughput)
- 有能力解决一些对于可用的内存来说太大的问题
- 最大化资源利用 - CPU/内存/网络/加速器(GPU)/电力

## 一些常用术语
1. Parallelism vs Concurrency
    - Parallelism: 多个进程同时且独立执行
    - Concurrency: 多个进程同时执行且共享至少一种资源
2. Processor, Die & Socket
    - Processor: 执行程序指令的电路。计算机系统中可能有许多处理器，例如图形处理器、视频处理器。在没有限定的情况下，通常指中央处理器
    - CPU: 计算机系统中主要的通用处理器（之一），而非特定用途（如视频解压缩）。
    - Die: 指硅晶片，包含处理器（通常是中央处理器）以及接口所需的其他组件（如内存控制器）。
    - Socket: 处理器和计算机主板之间的物理接口，它定义了处理器与主板连接的方式。不同的处理器和主板可能需要不同类型的Socket。
3. Core & Thread
    - Core: 核心是CPU内部的一个物理处理单元，能够独立执行计算任务。每个核心可以独立处理指令和执行计算操作。
    - Thread: 线程是操作系统能够进行计算调度的最小单位。它是程序执行流的一个单一顺序，可以被操作系统调度（启动、停止、挂起等）。
    - 核心和线程共同定义了处理器的处理能力
4. Node
    - 指一个服务器节点（一台计算机）
5. Cluster/Supercomputer
    - 成百上千个节点组成集群
6. Single precision floating-point
    - 通常占用32位（4字节）的存储空间，C语言中的float32类型，1符号位，8指数位，23有效数字位
7. Double precision floating-point
    - 通常占用64位（8字节）的存储空间，C语言中的float64类型，1符号位，11指数位，52有效数字位
8. Flop
    - Floating-point operations per second

## 如何量化/评估性能
公式如下👇

$R_{peak} = 2\times w_{vec} \times r_{clock} \times n_{core} \times n_{socket}$

变量解释：
1. $R_{peak} - $峰值理论性能
2. $w_{vec} - $向量宽度，表示每个处理器核心每个时钟周期内可以执行的浮点运算数。
3. $r_{clock} - $表示处理器核心每秒钟可以执行的时钟周期数。
4. $n_{core} - $表示单个处理器（CPU）或计算节点中的核心数量。
5. $n_{socket} - $表示系统中处理器（CPU）的数量。

**Linpack性能测试**：Linpack性能测试是一种衡量计算系统解决高密度线性代数问题能力的测试。这个测试通过测量系统在执行大规模双精度（64位）浮点算术矩阵运算时的性能来评估计算机的速度和效率。Linpack测试的一个典型应用是计算给定大小的矩阵$A$和向量$b$，求解线性方程组$Ax = b$
# Week2
## Plot programs performance
用"Arithmetic Intensity"，记作$I(n)$，来评估性能。$I(n) = {W(n)\over Q(n)}$。

$W(n)$:程序执行flops的次数，$Q(n)$:从内存传输到缓存的字节数。

- 低Arithmetic Intensity的程序叫内存受限程序
- 高Arithmetic Intensity的程序叫计算受限程序
- 对于内存受限的程序，处理器需要花费更多时间等待操作数从内存中传送出来（更多的时间花费在访问内存上，而不是运算上）。

### Roofline Model
Roofline Model是帮助了解软件性能的可视化工具。

Roofline Model两个组成部分
- **峰值性能（$R_{peak} / R_{max}$）**：这是计算系统在理想情况下可以达到的最高计算性能，通常以每秒浮点运算次数（FLOPS）来衡量。峰值性能由处理器的硬件特性决定，比如核心数量、时钟频率和向量化能力。图中水平线就是峰值性能
- **内存带宽（Memory Bandwidth）**：这是计算系统在单位时间内能从内存中读写数据的最大速率，通常以每秒传输的字节数（Bytes/s）来衡量。内存带宽是由系统的内存架构和内存类型决定的。带角度的斜线表示内存带宽
## 冯·诺伊曼
Von Neumann架构图如下所示👇
![The von Neumann Architecture](/img/comp328/vonNeumann.png)
- 由控制单元和算术/逻辑单元组成的CPU。
- 独立的存储区，可存储指令和数据。
- 指令由CPU执行，因此必须将指令从存储器带入CPU。
- 数据也必须从存储器进入CPU才能执行。
- CPU包含寄存器，作为临时存储的刮板。
- **The von Neumann bottleneck:** 数据和指令共用一条总线，因此指令获取和数据操作不能同时进行。

### 冯·诺伊曼瓶颈
1. 从内存中抓取对应程序计数器的指令
2. 解码指令
3. 从内存中抓取数据
4. 执行指令
5. 写回结果

### Pipelining
**Pipelining的基本概念**

流水线技术通过将指令的执行过程分解为多个阶段，并让不同的指令在不同的时间并行处理这些阶段来提高处理速度。这就好比是在组装线上，每个工人负责组装线上的一个特定任务，产品可以更快地完成，因为多个任务是在同时进行，而不是一个接一个地完成。

**在von neumann cycle中的应用**

在应用流水线技术后，处理器可以在完成当前指令的某个阶段的同时，开始执行下一条指令的前一个阶段。例如，当第一条指令在执行阶段时，第二条指令可以同时进行译码，第三条指令可以进行取指。这样，虽然每条指令的执行仍然需要串行经过所有阶段，但处理器可以在同一时刻处理多条指令的不同阶段，从而大大提高了指令的吞吐率。

### 对抗冯·诺伊曼瓶颈的方法
> 在芯片上添加高速缓存（cache)，但高速缓存也存在问题

例如，高速缓存越大，数据访问速度越慢。可以采用多级缓存架构，通过在处理器和主内存之间引入多个层级的缓存，旨在平衡缓存大小、访问速度和命中率之间的关系。

高速缓存利用了程序的空间局部性（spatial locality）和时间局部性（temporal locality）。

- 时间局部性指的是在较短的时间内，被访问过一次的数据项很可能在不久的将来再次被访问的特性。这种访问模式意味着一旦数据被加载到缓存中，它很可能很快再次被需要，因此保留这些数据项在缓存中可以减少对较慢主存的访问次数。
- 空间局部性是指如果一个数据项被访问，那么其附近的数据项很快也可能被访问的特性。这种模式基于数据存储的物理结构，相邻的数据项通常也在内存中相邻存储。高速缓存系统利用这一特性通过预取附近的数据项到缓存中，即使这些数据项还没有被显式请求。

AMD Bulldozer 服务器插槽的内存层次结构
![AMD Bulldozer 服务器插槽](/img/comp328/Hwloc.png)


## How to gain performance form a single core/socket
```java
for (int i = 0; i<1000; i++) {
    b[i] = a[i]*a[i];
}
```
对于上面这个程序，应该运行1000个clock cycles。假如一个clock cycle不是做一次迭代，而是做4次迭代，那么总共需要250个clock cycles。这就叫vector processing，也叫Single Instruction, Multiple Data（SIMD）。

在单核上压榨更多性能：SMT(simultaneous multithreading)，通过在单个物理CPU核心上同时执行多个线程来提高处理器的效率和性能。SMT允许单个核心像操作系统和应用程序呈现出多个逻辑核心或线程，使得处理器可以更有效地利用其资源，特别是在一个线程等待数据访问或执行长时间操作时，处理器可以转而执行另一个线程的任务。

# Week3
## 编译器优化的常用方法
两种优化方式：
1. 时间优化
2. 空间优化

编译器会自动的做一些优化。

von Neumann cycle中的执行阶段也需要对内存进行读写。所有的算术操作都需要读写交替进行。编译器的工作就是给特定硬件确定合理的交错顺序。

读数据的方式对性能表现来说很重要（cache的存在就是为了减少处理器访问主存的次数）。

把多维数据存储成单维数据的两种方法
- row major，C/C++/Java通常用row major
- column major，Fortran/Pascal通常用column major

常用优化方法
1. Inlining
```c
float add(int a, int b){
float results = a + b;
return result;
}
int main(NULL){
float a = 3.6;
float b = 6.3;
float result = add(a, b);
}
```
编译器会把所有的函数用inline code代替，消除函数调用的开销，包括压栈、跳转和返回等操作。Inlining后👇
```c
int main(NULL){
float a = 3.6;
float b = 6.3;
float result = a+b;
}
```
缺点：如果一个函数在多个地方被内联，那么可执行文件的大小可能会增加，这有时被称为代码膨胀。而且在某些情况下，如果内联导致生成的代码过大，可能会降低指令缓存的效率，反而减慢程序的运行速度。

2. Dead code / Dead store
    - Dead code: 由于一些条件，这部分代码永远无法执行
    - Dead store: 计算过但从未使用过的变量
    编译器找到dead code和dead store并安全地忽略他们。
3. Code hoisting （代码提升）
```c
for(i = 0; i < N; i++){
    x[i] = i * 5 * pi;
}
```
把常量提出来，防止重复计算👇。!: 过度使用可能会导致寄存器溢出
```c
v = 5 * pi;
for(i = 0; i < N; i++){
x[i] = i * v;
}
```

4. Common Sub-expression
```c
y = a * log(x) + pow(log(x), 2);
```
👇
```c
v = log(x);
y = a * v + pow(v, 2);
```
5. Loop unrolling
```c
for(i = 0; i < N; i++){
x[i] = i * 5 * pi;
}
```
👇
```c
x[1] = 1 * 5 * pi;
x[2] = 2 * 5 * pi;
x[3] = 3 * 5 * pi;
...
x[N] = N * 5 * pi;
```

以上优化方式都是基于时空交换（time-space trade-off）。通常想节省执行时间就要增加代码体量。通常优化程度越高，编译时间越长，可执行文件越大。
## 生成优化报告
Compiler的优化指令
- -O0/-O 禁用所有优化
- -O1 使用最简单的优化方法
- -O2 所有O1的优化方法，再加一些更高级的优化方法，这里开始出现时空交换的优化方法。Recommended
- -O3 比O2更强劲，涉及大量的时空交换方法，编译时间显著增加，建议用于有密集浮点运算循环的代码
- -Os 针对可执行文件的大小进行优化
- -O2-no-vec 没有vectorisation的O2优化

**Intel的生成报告指令**

-qopt-reportN，N=0，1，2，3，4，5。0表示没有报告，5表示最详尽的报告
```shell
icc program.c -qopt-report3
```
## 利用Profiling code确定优化位置
Profiling: 测量程序的行为和性能，包括运行时和资源利用情况。对程序进行细分并找到热点部分，对热点部分进行优化。

分析热点部分：
- 内存带宽?
- 寄存器的数量?
- cache利用率?
- 代码太烂?

# Week4
## 如何实现parallelising a program
1. 识别parallelism机会
2. 选择parallelism策略
3. 使用工具和库(OpenMP, CUDA...)
4. 实现+调试
5. 性能测试+优化

把问题拆解成并行组件的普遍方法
1. Data parallelism
2. Task parallelism
3. Pipelines
4. Mixed Solutions

## 粒度
1. 粗粒度parallelism
粗粒度并行涉及较大的任务，每个任务包含相对较多的计算量。这种并行度较低，因为程序被分解成较少的、但每个都比较大的部分，在多个处理单元上执行。相比于细粒度并行，粗粒度并行的管理和通信开销相对较低，因为任务之间的交互较少。
2. 细粒度parallelism
细粒度并行指的是由很小的任务组成的并行计算，每个任务执行的计算量相对较少。它允许高度的并行度，因为程序被分解成许多小的部分可以在多个处理单元上并行执行。细粒度并行的挑战在于管理和协调大量小任务的开销可能会很大，特别是当通信和同步成本高于任务执行成本时。
## 衡量并发性能
并行编程模型
- Shared Memory Programming: 在共享内存编程模型中，所有处理器都访问同一个物理内存空间。这意味着所有的并行执行线程都可以直接读写同一块内存地址空间中的数据。这种模型简化了数据的共享，因为不需要显式地在处理器之间传递消息来共享数据。共享内存模型通常用于多核处理器或多处理器计算机系统，其中所有核心都能够访问同一个全局内存。OpenMP就是共享内存并行编程的API
- Distributed Memory Programming: 在分布式内存编程模型中，每个处理器或计算节点拥有自己的局部内存，处理器之间通过网络或总线传递消息来交换数据。这种模型要求显式地在不同的处理器之间发送和接收数据，通常使用消息传递接口（如MPI）来实现。分布式内存模型适用于计算集群、多处理器系统或网络连接的计算机，每个节点运行其进程并通过消息传递进行通信和数据共享。MPI(Message Passing Interface)就是分布式内存并行编程标准，对共享内存也适用。

**Scalability and Speedup**
- Speedup指不用并行编程运行程序所花的时间和使用并行编程运行程序所花的时间的比值
- Scalability指多添加一个核/处理器的情况下，speedup会有多少提升

- $t_1$: 程序在单核（或单处理器）上运行的时间。
- $t_p$: 程序在p个核心（或处理器）上运行的时间。
- $S_p = {t_1\over t_p}$: 加速比是衡量并行程序相对于其顺序版本的性能提升的指标。理想情况下，当你用p个处理器来运行程序时，程序的执行时间会变为单处理器上的$1\over p$，然而，由于通信和同步开销以及代码中不可并行化的部分，实际加速比往往低于p。
- 并行效率公式$e_p = {S_p\over p}$: 并行效率是衡量加速比相对于使用的处理器数的效率。它显示了并行资源的利用程度，通常表示为百分比。

**Multi-node scaling measurements**
- Weak Scaling: 在弱扩展性测试中，随着节点数量的增加，每个节点上的工作负载保持不变。理想情况下，总体工作负载随节点数线性增加，执行时间保持恒定。这样可以测量系统增加计算资源时维持相同性能的能力。
- Strong Scaling: 强扩展性是指总体工作负载保持不变，而节点数增加。理想情况下，执行时间随节点数的增加而减少。这种测量体现了系统处理固定大小工作负载的效率。

**Amdahl’s Law**
程序的最快执行速度受限于那些必须串行执行的代码部分。这些串行部分的总执行时间设置了程序加速的下限。无论并行处理多么高效，总体性能提升永远不能超过这个下限。
- $\alpha$原始问题中串行部分所占的比例（就时间而言）
- $t_p = {\alpha\times t_1 + {(1-\alpha)\times t_1\over p}}$
- $S_p = {t_1\over t_p} , limit = {1\over\alpha}$
- 最大可能的speedup是$1\over\alpha$

**Gustafson’s Law**
Gustafson's Law的出发点是，随着处理器数量的增加，人们倾向于解决更大规模的问题，而不是简单地加速固定大小的问题。因此，他认为：
- 总工作量的增加：随着处理器数量的增加，我们不仅仅是将相同的任务分配给更多的处理器，而是增加了总体的工作量，以便填满并利用所有可用的计算资源。
- 串行部分的影响减少：当总工作量增加时，程序中的串行部分所占的比例变得不那么重要，因为绝对的串行处理时间相对于总处理时间的影响变小了。
- 并行部分的增加：与此同时，可并行化的部分在总工作量中占据了更大的比例，因为这些部分可以在所有的处理器上同时进行。
- Speedup = $\alpha + p(1-\alpha)$

## 几个并发问题的例子

# Week5
# 并行解决方案的正确性
## Round errors
## Race conditions
# 克服race conditions

# 计算模型
